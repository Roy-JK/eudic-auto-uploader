import sys
import os
import re
import requests
import feedparser
import pandas as pd
import yaml  # <--- [æ–°å¢] å¿…é¡»å®‰è£…: pip install PyYAML
from dateutil import parser as date_parser
from urllib.parse import urlparse
import shutil

# ================= é…ç½®åŠ è½½é€»è¾‘ (Config Loading) =================

CONFIG_FILE = "config.yaml"


def load_config():
    """
    è¯»å– YAML é…ç½®æ–‡ä»¶
    è¿”å›ä¸€ä¸ª Python å­—å…¸ï¼Œä¾‹å¦‚: {'rss_feeds': {...}, 'year_from': 2025}
    """
    if not os.path.exists(CONFIG_FILE):
        print(f"âš ï¸  è­¦å‘Š: æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ {CONFIG_FILE}ï¼Œå°†ä½¿ç”¨ä»£ç å†…çš„é»˜è®¤å€¼ã€‚")
        return {}

    try:
        with open(CONFIG_FILE, "r", encoding="utf-8") as f:
            # yaml.safe_load æ˜¯å°† yaml æ–‡æœ¬è½¬ä¸º python å­—å…¸çš„æ ¸å¿ƒå‡½æ•°
            return yaml.safe_load(f) or {}
    except Exception as e:
        print(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return {}


# 1. åœ¨æ¨¡å—åŠ è½½æ—¶ï¼Œç«‹å³æ‰§è¡Œè¯»å–
_config = load_config()

# 2. åˆå§‹åŒ–å…¨å±€å˜é‡
# è¿™é‡Œå®ç°äº† yaml(å°å†™) åˆ° python(å¤§å†™) çš„æ˜ å°„
# å¦‚æœ yaml é‡Œæ²¡å†™æˆ–è€…è¯»ä¸åˆ°ï¼Œå°±ç”¨é€—å·åé¢çš„é»˜è®¤å€¼
RSS_FEEDS = _config.get("rss_feeds", {})
YEAR_FROM = _config.get("year_from", 2025)
LATEST_NUM = _config.get("latest_num", 2)
DOWNLOAD_FOLDER = _config.get("download_folder", "rss_download")

# ================= å·¥å…·å‡½æ•° =================


def parse_duration(dur_raw: str) -> str:
    if not dur_raw:
        return ""
    parts = dur_raw.split(":")
    try:
        parts = [int(p) for p in parts]
        total_sec = sum([x * 60**i for i, x in enumerate(reversed(parts))])
        m, s = divmod(total_sec, 60)
        return f"{m}:{s:02d}"
    except ValueError:
        return dur_raw


def sanitize_filename(name: str) -> str:
    name = re.sub(r'[\\/:"*?<>|]+', "", name).strip()
    return re.sub(r"\s+", "-", name)


def parse_rss(url):
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) Chrome/120.0.0.0 Safari/537.36"
    }
    try:
        response = requests.get(url, headers=headers, timeout=15)
        feed = feedparser.parse(response.content)
    except Exception as e:
        print(f"Error fetching {url}: {e}")
        return []

    rows = []
    for entry in feed.entries:
        raw_date = entry.get("published", entry.get("pubDate", ""))
        try:
            dt = date_parser.parse(raw_date)
            date_str = dt.strftime("%Y-%m-%d")
            file_date = dt.strftime("%Y%m%d")
        except Exception:
            date_str = file_date = ""

        title = entry.get("title", "").strip()
        summary = entry.get("summary", "").strip()
        duration_fmt = parse_duration(entry.get("itunes_duration", ""))

        audio_link = ""
        if entry.get("enclosures"):
            audio_link = entry.enclosures[0].get("href", "")
        link = audio_link or entry.get("link", "")

        rows.append(
            {
                "æ—¥æœŸ": date_str,
                "æ–‡ä»¶æ—¥æœŸ": file_date,
                "é¢˜ç›®": title,
                "ç®€ä»‹": summary,
                "æ—¶é•¿": duration_fmt,
                "é“¾æ¥": link,
            }
        )
    return rows


def download_audios(rows, subfolder, year_limit, num_limit):
    """
    ä¸‹è½½é€»è¾‘ï¼šæ¥æ”¶ year_limit å’Œ num_limit å‚æ•°ï¼Œä¸å†ä¾èµ–å…¨å±€å˜é‡
    """
    out_dir = os.path.join(DOWNLOAD_FOLDER, subfolder)
    os.makedirs(out_dir, exist_ok=True)

    filtered_rows = [
        item
        for item in rows
        if item["é“¾æ¥"]
        and item["æ–‡ä»¶æ—¥æœŸ"][:4].isdigit()
        and int(item["æ–‡ä»¶æ—¥æœŸ"][:4]) >= year_limit
    ]
    filtered_rows.sort(key=lambda x: x["æ–‡ä»¶æ—¥æœŸ"], reverse=True)

    if num_limit != -1:
        filtered_rows = filtered_rows[:num_limit]

    for item in filtered_rows:
        datepart = item["æ–‡ä»¶æ—¥æœŸ"]
        titlepart = sanitize_filename(item["é¢˜ç›®"])
        ext = os.path.splitext(urlparse(item["é“¾æ¥"]).path)[1] or ".mp3"
        fname = f"{datepart}-{titlepart}{ext}"
        dest = os.path.join(out_dir, fname)

        if os.path.exists(dest):
            continue

        print(f"Downloading â†’ {fname}")
        try:
            resp = requests.get(item["é“¾æ¥"], stream=True, timeout=60)
            resp.raise_for_status()
            with open(dest, "wb") as f:
                for chunk in resp.iter_content(8192):
                    f.write(chunk)
        except Exception as e:
            print(f"  âœ— failed: {e}")


# ================= ä¸»å…¥å£ (æ”¯æŒä¼ å‚è¦†ç›– YAML é…ç½®) =================


def fetch_rss_main(
    target_feeds=None, year_from=None, latest_num=None, clean_folder=True
):
    """
    å‚æ•°è¯´æ˜:
    - target_feeds: (Dict) è‡ªå®šä¹‰ä¸‹è½½åˆ—è¡¨ã€‚å¦‚æœä¸ä¼ ï¼Œåˆ™ä½¿ç”¨ YAML ä¸­çš„å…¨å±€é…ç½®ã€‚
    - year_from: (Int) è‡ªå®šä¹‰å¹´ä»½ã€‚å¦‚æœä¸ä¼ ï¼Œåˆ™ä½¿ç”¨ YAML é…ç½®ã€‚
    - latest_num: (Int) è‡ªå®šä¹‰æ•°é‡ã€‚å¦‚æœä¸ä¼ ï¼Œåˆ™ä½¿ç”¨ YAML é…ç½®ã€‚
    - clean_folder: (Bool) æ˜¯å¦æ¸…ç©ºç›®å½•ã€‚é»˜è®¤ä¸º Trueã€‚
    """

    # 1. ä¼˜å…ˆçº§é€»è¾‘ï¼šå‡½æ•°å‚æ•° > YAMLå…¨å±€é…ç½®
    feeds_to_use = target_feeds if target_feeds is not None else RSS_FEEDS
    year_to_use = year_from if year_from is not None else YEAR_FROM
    num_to_use = latest_num if latest_num is not None else LATEST_NUM

    # 2. æ¸…ç†ç›®å½•é€»è¾‘
    if clean_folder and os.path.exists(DOWNLOAD_FOLDER):
        print(f"ğŸ§¹ æ£€æµ‹åˆ°æ—§ç›®å½• [{DOWNLOAD_FOLDER}]ï¼Œæ­£åœ¨å½»åº•åˆ é™¤...")
        try:
            shutil.rmtree(DOWNLOAD_FOLDER)
            print("âœ… æ—§ç›®å½•å·²æ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ åˆ é™¤æ—§ç›®å½•å¤±è´¥: {e}")
        print("")

    print(f"=== å¼€å§‹ RSS ä¸‹è½½ä»»åŠ¡ (å¹´ä»½>={year_to_use}, æ•°é‡={num_to_use}) ===")

    for name, url in feeds_to_use.items():
        print(f"\nğŸ“¥ å¤„ç† {name} ...")
        data = parse_rss(url)
        if not data:
            print(f"âš ï¸  æ— æ•°æ®: {name}")
            continue

        out_dir = os.path.join(DOWNLOAD_FOLDER, name)
        os.makedirs(out_dir, exist_ok=True)

        df = pd.DataFrame(data)
        excel_path = os.path.join(out_dir, f"{name}.xlsx")
        df.to_excel(excel_path, index=False)

        # ä¼ å…¥ç¡®å®šå¥½çš„å‚æ•°
        download_audios(
            data, subfolder=name, year_limit=year_to_use, num_limit=num_to_use
        )
        print(f"âœ… {name} å¤„ç†å®Œæˆ")

    print("\n=== ä¸‹è½½ä»»åŠ¡ç»“æŸ ===")


if __name__ == "__main__":
    # æ— å‚æ•°è¿è¡Œï¼Œåˆ™ä½¿ç”¨ config.yaml çš„é…ç½®
    # fetch_rss_main()

    fetch_rss_main(
    target_feeds={
        "Disney Magic of Storytelling": "https://feeds.megaphone.fm/ESP4559331002"
    },
    year_from=2024,
    latest_num=10
)
